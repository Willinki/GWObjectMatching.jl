* Documentation 

In this document, we describe the algorithms that we implemented to compute the Gromov-Wasserstein barycenters we talk about in theory.org.


** MetricMeasureSpace.jl
In this file we implement the struct we talk about in implementation.org.


** RepeatUntilConvergence 
The mutable struct "RepeatUntilConvergence{T}" is useful for iterate a function: it contains:
    - an update function, that is the function that we need to iterate on something of type T;
    - a criterion for convergence, that checks if we have to stop the execution, using the history;
    - the history, under the form of a "CircularBuffer", which can be thought as a Vector{T} with fixed dimension
    - an initial value of type T.

Then the function "execute!" just do the process we described above: it takes the initial value, it applies the update function on it and stores 
the new element in the history to check if the stop criterion is satisfied; if it's not it continues the execution.


** SinkhornKnopp.jl
The Sinkhorn-Knopp algorithm is an iterative algorithm which computes an (approximate) solution of the following minimum problem: 
$$\min \; C \cdot \T + \varpesilon KL(T),$$
where the minimum is taken over all the transport plans between two fixed marginal distributions p and q, $\varepsilon$ is a fixed 
(small) constant and KL is the Kullback-Leibler divergence.

*** struct data_SK
The struct "data_SK" contains all the necessary to compute a single update of the Sinkhorn-Knopp algorithm.

#+begin_src julia :results output
struct data_SK:
    K::Matrix{Float64} 
    p::Vector{Float64} 
    q::Vector{Float64} 
    T::Matrix{Float64}       
    a::Vector{Float64}       
    b::Vector{Float64}
    inner_constructor(K,p,q,T)   
end
#+end_src

**** K 
The matrix K is the element-wise exponentiation of C/epsilon, so it must be used only with this setting.


**** p and q 
These two vectors are the marginal distributions, so they must be non-negative and with sum 1.

**** T 
T is a feasible transport plan between p and q.

**** a and b 
They are the vectors that are updated by the Sinkhorn algorithm.

**** inner_constructor
It takes just K, p, q and T. It just checks that the dimensions of this object are correct, and then it built an element of type data_SK with
K, p, q, T, a \= constant vector with sum 1 (it actually could be any initialization, we just decided for this one) and $b \= \frac{q}{K^T*a}$
     
*** Function update_SK 
Arguments: an element of type data_SK. 
Output: it computes a single iteration of the Sinkhorn algorithm updating a, b and T in the following way: 
     $$a = \frac{p}{K*b}, \quad b = \frac{q}{K^T*a}, \quad T = diag(a)*K*diag(b)$$

*** Function compute_marginals 
Arguments: a squared  matrix.
Output: two vector, which are obtained summing all the rows and all the columns (one must think the matrix as the element T of a data_SK and 
the hope is that this two vectors are "similar" to p and q).

*** Function stop_SK_T
Arguments: a vector history, of size at least 2, of elements of type data_SK and a float tol, which is the tolerance. 
Output: it returns true if the 1-norm between history[end].T and history[end-1].T is less than tol, otherwise it return false.

*** Function stop_SK_ab_old
Arguments: a vector history, of size at least 1, of elements of type data_SK and a float tol, which is the tolerance. 
Output: it computes the marginals $\mu$ and $\nu$ of history[end].T and it returns true if both the 1-norm of history[end].p-$\mu$ and 
history[end-1].q-$\nu$ are less than tol, otherwise it return false.

*** Function stop_SK_ab_new
Arguments: a vector history, of size at least 1, of elements of type data_SK and a float tol, which is the tolerance. 
Output: it does exactly the same of stop_SK_ab_old without using directly the T filed of the struct, but recomputing it using a, b and K fields.

*** Function stop_SK
Arguments: a vector history, of size at least 1, of elements of type data_SK and a float tol, which is the tolerance. 
Output: it returns true if both stop_SK_T and stop_SK_ab_new return true on the same arguments, otherwise it returns false (this is the
most precise stop criterion, since it checks both the difference betwwen the updating of the transport and how much the marginal distributions
are different from the ones we want).


** loss.jl
In this file we built a simple struct "loss" to make more compact the syntax in the future algorithms concerning the chosen of the loss function.

The theory tells us that the Gromov-Wasserstein distance between two finite metric measure spaces $(C,\mu)$ and $(D,\nu)$ is given by 
$$GW((C,\mu),(D,\nu)) = \min_T \sum_{i,j,k,l} L(C_{ik},D_{jl})T_{ij}T_{kl},$$
where the infimum is taken over all the transport plans T between the marginals $\mu$ and $\nu$. In a more compact way, we will write the
expression above as $\langle L\otimes T , T\rangle$, where the matrix $L(C,D)\otimes T$ is defined as 
$$(L(C,D) \otimes T)_{kl} = L(L(C_{ik},D_{jl})T_{ij}).$$

So, to define the Gromov-Wasserstein distance, we need a function $L:\mathbb{R} \to \mathbb{R}$, called loss function. The only admissible
functions for this work are the L2 loss and the KL loss, defined as 
$$L2(a,b) = (a-b)^2,\quad KL(a,b) = a\log(a/b) -a +b.$$

In general, for this algorithm, one can consider loss functions that can be written as $L(a,b) = f_1(a) + f_2(b) - h_1(a)h_2(b)$ (note that 
L2 and KL can be written in this way). This form is important for the computation of the tensor product $L(C,D)\otimes T$, that can be computed 
using the following formula
$$L(C,D) \otimes T = f_1(C) *\mu * ones(n)^T + ones(m) *\nu * f_2(D)^T -h_1(C) *T * h_2(D)^T,$$
where n is the size of $(C,\mu)$, m is the size of $(D,\nu)$, the exponentiation to T is the transpose and the functions f1, f2, h1, h2 
are applied element-wise.

*** struct loss
It contains all the informations we talked above regarding a loss function.

#+begin_src julia :results output
struct Loss:
    string::String
    f1::Function
    f2::Function
    h1::Function
    h2::Function  
end
#+end_src

**** string
It contains the name of the loss function. The only admissible strings are "L2" and "KL", to distinguish when we use the Euclidean loss or the 
Kullback-Leibler one.

**** f1, f2, h1, h2
They take a float and give another float. They are defined according to the structure above, depending if string=L2 or string=KL.

**** inner constructor
Argument: a string
Output: if the string is "L2" or "KL", it defines the function fields according to the decomposition above, otherwise it raises an error.

*** Function GW_cost
Arguments: a Loss field, two metric measure spaces $M=(C,\mu)$ and $N=(D,\nu)$, a matrix of floats, a float $\varepsilon$.
Output: it computes the tensor product $E = L(C,D)\otimes T$ (it raises an error if the size are not compatible) and then it returns the
component-wise exponentiation of $E/\varepsilon$, so that the output is ready to be given in input as field K of a data_SK, so that it can be
used for the Sinkhorn algorithm.